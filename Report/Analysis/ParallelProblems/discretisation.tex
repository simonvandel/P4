\section{Discretisation}
\label{dis}

Discretization concerns the process of transferring continuous models and equations into discrete counterparts. But whenever continuous data is discretized, there is always some amount of discretization error.

\ephm{discrete}
In the field of simulation, a discrete-event simulation (DES), models the operation of a system as a discrete sequence of events in time. Each event occurs at a particular instant in time and marks a change of state in the system.[1] Between consecutive events, no change in the system is assumed to occur; thus the simulation can directly jump in time from one event to the next.
\ephm{continuous}
This contrasts with continuous simulation in which the simulation continuously tracks the system dynamics over time. Instead of being event-based, this is called an activity-based simulation; time is broken up into small time slices and the system state is updated according to the set of activities happening in the time slice.[2] Because discrete-event simulations do not have to simulate every time slice, they can typically run much faster than the corresponding continuous simulation.
\ephm{process}
Another alternative to event-based simulation is process-based simulation. In this approach, each activity in a system corresponds to a separate process, where a process is typically simulated by a thread in the simulation program.[2] In this case, the discrete events, which are generated by threads, would cause other threads to sleep, wake, and update the system state.

\subsection{Granuality}

      Computation / Communication Ratio:

          In parallel computing, granularity is a qualitative measure of the ratio of computation to communication.

          Periods of computation are typically separated from periods of communication by synchronization events.

      \emph{Fine-grain Parallelism:}

          Relatively small amounts of computational work are done between communication events

          Low computation to communication ratio

          Facilitates load balancing

          Implies high communication overhead and less opportunity for performance enhancement

          If granularity is too fine it is possible that the overhead required for communications and synchronization between tasks takes longer than the computation.

      \ephm{Coarse-grain Parallelism:}

          Relatively large amounts of computational work are done between communication/synchronization events

          High computation to communication ratio

          Implies more opportunity for performance increase

          Harder to load balance efficiently

  Space
  Time
