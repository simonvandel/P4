%Parallelitet:
%- Hvorfor lave noget parallelt?
%- Hvorfor er parallelitet fremtiden?
%  - Fysisk grænse for hvor hurtigt en processor kan køre
%Hvorfor sprog til det (merge måske med intro):
%- Flere og flere får adgang til clusters længere "nede" og man kan bygge små distribueret systemer lokalt (processor kort til din stationære)
%  - Snak om at det derfor skal være simpelt


\subsection{Parallelism}\cite{parallel programming languages}.

In the continued effort of trying to squeeze as much power out of computers as possible, the computer scientific community is at a point where increasing the clock speed of processors is no longer as viable a solution as it used to be. This has spawned an increased interest in increasing computational power in other ways, one being parallelism.

Parallelism is the act of dividing calculations into independently solvable parts, and then solving them on multiple processors before finally gathering the individual results and combining them. The main benefit of parallelising anything is to gain \emph{speed up} in the computation time of problems. This will be described in \cref{sup}.

With parallelism you gain \emph{speed up} through combining multiple processing units. This is seen in newer CPU's as multiple cores, but on a larger scale this principle can be used to create supercomputers, capable of performing immense calculations.

But even without a supercomputer a distributed network of multiple computers can provide with large amounts of parallel computing power. With this being a foreseeable future, we predict an increase in the access to, and need for, parallel systems.